{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/debasmitroy/Desktop/programming/gemini-agent-assist/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import langgraph\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "import os\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Any\n",
    "from utils.gemini_service import GeminiModel, GeminiJsonEngine, GeminiSimpleChatEngine\n",
    "from utils.logger import LOGGER\n",
    "import time\n",
    "import json\n",
    "\n",
    "import hashlib\n",
    "from sqlalchemy import create_engine, Column, String, Table, MetaData\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.sql import text\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/Users/debasmitroy/Desktop/programming/gemini-agent-assist/key.json\"\n",
    "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = \"hackathon0-project\"\n",
    "os.environ[\"GOOGLE_CLOUD_LOCATION\"] = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pydantic Base Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Query(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents a financial query involving placeholders for key financial attributes: \n",
    "    <BUIS>, <DATE>, <NET>, <FACTOR>, <PROF_LOSS>, <CUR>, <PF>, and <DSK>.  \n",
    "\n",
    "    Example Queries:  \n",
    "    - What are the <FACTOR>s that contributed the highest <NET> profit/loss?  \n",
    "    - Which <CUR> currencies are driving the top-performing portfolios <PF>?  \n",
    "    \"\"\"\n",
    "    query: str = Field(..., title=\"Financial query using placeholders <BUIS>, <DATE>, <NET>, <FACTOR>, <PROF_LOSS>, <CUR>, <PF>, and <DSK>.\")\n",
    "\n",
    "class FinancialQueries(BaseModel):\n",
    "    \"\"\"\n",
    "    A collection of structured queries designed to generate financial summaries.  \n",
    "    Each query should use placeholders (<FIELD>) instead of actual values.  \n",
    "    \"\"\"\n",
    "    queries: List[Query] = Field(..., title=\"List of financial queries using placeholders <FIELD> instead of actual values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQLScript(BaseModel):\n",
    "    \"\"\"\n",
    "    SQL Script to query data from the given table. You have to use this tool to generate the SQL script.\n",
    "    \"\"\"\n",
    "    sql_script: str = Field(..., title=\"SQL Script to query data from the given table.\")\n",
    "    columns: List[str] = Field(..., title=\"Which columns are being projected in the SQL script.\")\n",
    "    description: str = Field(..., title=\"What does the SQL script do in Finance Analyst's perspective\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    state: str\n",
    "    model: Dict[str, Any]\n",
    "    results: Dict[str, Any]\n",
    "    cache_location: Dict[str, Any]\n",
    "    cache_flag: Dict[str, Any]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_data(path: str) -> Dict[str, Any]:\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def save_json_data(path: str, data: Dict[str, Any]):\n",
    "    # Create the directory if it doesn't exist\n",
    "    directory = os.path.dirname(path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    with open(path, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "def load_cached_results(state):\n",
    "    # Load the data from cache if the cache flag is set to True\n",
    "    if state['cache_flag'][state['state']]:\n",
    "        cached_result = load_json_data(state['cache_location'][state['state']])\n",
    "        if cached_result:\n",
    "            state['results'][state['state']] = cached_result['result']\n",
    "            LOGGER.info(f\"State: {state['state']} | Loaded cached data and skipping the model, {len(state['results'][state['state']])} old result found\")\n",
    "            return state\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InMemoryDB:\n",
    "    def __init__(self):\n",
    "        self.engine = create_engine('sqlite:///:memory:', echo=False)\n",
    "        self.metadata = MetaData()\n",
    "        self.Session = sessionmaker(bind=self.engine)\n",
    "        self.session = self.Session()\n",
    "\n",
    "    def create_table(self, table_name, columns):\n",
    "        \"\"\"Creates a table dynamically with a SHA-256 hash primary key to prevent duplicates.\"\"\"\n",
    "        table = Table(\n",
    "            table_name, self.metadata,\n",
    "            Column(\"id\", String, primary_key=True),  # Primary key hash column\n",
    "            *[Column(col, String) for col in columns],\n",
    "        )\n",
    "        table.create(self.engine)\n",
    "\n",
    "    def generate_hash(self, data):\n",
    "        \"\"\"Generates a SHA-256 hash over the string representation of a row.\"\"\"\n",
    "        row_string = str(sorted(data.items()))  # Ensure consistent ordering\n",
    "        return hashlib.sha256(row_string.encode()).hexdigest()\n",
    "\n",
    "    def insert_data(self, table_name, data):\n",
    "        \"\"\"Inserts a row into the table using parameterized queries and avoids duplicates.\"\"\"\n",
    "        data[\"id\"] = self.generate_hash(data)  # Add hash key to data\n",
    "        placeholders = \", \".join([f\":{key}\" for key in data.keys()])\n",
    "        query = text(f\"\"\"\n",
    "            INSERT INTO {table_name} ({', '.join(data.keys())})\n",
    "            VALUES ({placeholders})\n",
    "            ON CONFLICT(id) DO NOTHING\n",
    "        \"\"\")\n",
    "        self.session.execute(query, data)\n",
    "        self.session.commit()\n",
    "\n",
    "    def query_data(self, query):\n",
    "        \"\"\"Executes a SELECT query and returns results with column names.\"\"\"\n",
    "        result = self.session.execute(text(query))\n",
    "        columns = result.keys()  # Get column names\n",
    "        data = result.fetchall()  # Get data rows\n",
    "\n",
    "        # Convert data to list of list from list of tuples\n",
    "        data = [list(row) for row in data]\n",
    "        return list(columns), data  # Return both columns and data\n",
    "\n",
    "    def __del__(self):\n",
    "        self.session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title_data_inmemory_db(rule_based_title_comment_data):\n",
    "    # Initialize DB and create table\n",
    "    columns = list(rule_based_title_comment_data[0].keys())\n",
    "    columns.remove(\"id\") if \"id\" in columns else None  # Ensure id isn't duplicated\n",
    "    inmemory_db = InMemoryDB()\n",
    "    inmemory_db.create_table(\"title_data\", columns)\n",
    "\n",
    "    # Insert data\n",
    "    for data in rule_based_title_comment_data:\n",
    "        inmemory_db.insert_data(\"title_data\", data)\n",
    "\n",
    "    return inmemory_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TITLE_DATA_INMEM_DB = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_agent(state: AgentState):\n",
    "    LOGGER.info(\"Starting the agent-assist\")\n",
    "    state['state'] = 'start'\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_agent(state: AgentState):\n",
    "    LOGGER.info(\"Ending the agent-assist\")\n",
    "    state['state'] = 'end'\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_old_summary_agent(state: AgentState):\n",
    "    state['state'] = 'refine_old_summaries'\n",
    "    LOGGER.info(f\"State: {state['state']} | Initializing the agent to refine old summaries\")\n",
    "\n",
    "    # Load the data from cache if the cache flag is set to True\n",
    "    cached_result = load_cached_results(state)\n",
    "    if cached_result:\n",
    "        return state\n",
    "    \n",
    "    # Initialize the model\n",
    "    gemini_simple_chat_engine = GeminiSimpleChatEngine(model_name=state['model']['model_name'], \n",
    "                                                   temperature=state['model']['temperature'],\n",
    "                                                   max_output_tokens=state['model']['max_output_tokens'],\n",
    "                                                   systemInstructions=\"You are an expert financial bot. You will be given a financial report and you need to refine the report. Keep everything in a single large paragraph. Dont use any markdown or bullet points. \",\n",
    "                                                   max_retries=state['model']['max_retries'],\n",
    "                                                   wait_time=state['model']['wait_time'])\n",
    "\n",
    "    # Old summaries from sample_summarized_pnl_commentaries (Note: This is a sample data not cached, admin will provide the data)\n",
    "    sample_summarized_pnl_commentaries = load_json_data(state['cache_location']['sample_summarized_pnl_commentaries'])\n",
    "    LOGGER.info(f\"State: {state['state']} | Loaded the sample data, {len(sample_summarized_pnl_commentaries)} old summaries found\")\n",
    "    \n",
    "    # Refine the old summaries\n",
    "    result = []\n",
    "\n",
    "    for summary in sample_summarized_pnl_commentaries:\n",
    "        _refinement_prompt = [\n",
    "            f\"Given financial report: {summary}\",\n",
    "            f\"Please refine the financial report in a more readable and meangingful way without losing any important information and entitites and technical/financial terms. Dont unnecessarily change the meaning of the report and dont increase the length of the report. \"\n",
    "        ]\n",
    "        refined_summary = gemini_simple_chat_engine(_refinement_prompt)\n",
    "        result.append(refined_summary)\n",
    "        LOGGER.info(f\"State: {state['state']} | Summary refined , {summary[:30]}... to {refined_summary[:30]}...\")\n",
    "\n",
    "    # Save the result to state var and set the cache flag to True\n",
    "    state['results'][state['state']] = result\n",
    "    state['cache_flag'][state['state']] = True\n",
    "\n",
    "    # Save the result to cache with the state name and {result} key\n",
    "    save_json_data(state['cache_location'][state['state']], {\"result\":state['results'][state['state']]})\n",
    "    \n",
    "    LOGGER.info(f\"State: {state['state']} | Refinement of old summaries completed, saved the result to cache and set the cache flag to True\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subj_query_agent(state: AgentState):\n",
    "    state['state'] = 'subj_query_generation'\n",
    "    LOGGER.info(f\"State: {state['state']} | Initializing the agent to refine old summaries\")\n",
    "\n",
    "    # Load the data from cache if the cache flag is set to True\n",
    "    cached_result = load_cached_results(state)\n",
    "    if cached_result:\n",
    "        return state\n",
    "    \n",
    "    # Initialize the model\n",
    "    fin_qry_engine =  GeminiJsonEngine(\n",
    "                                    model_name=state['model']['model_name'],\n",
    "                                    basemodel=FinancialQueries,\n",
    "                                    temperature=state['model']['temperature'],\n",
    "                                    max_output_tokens=state['model']['max_output_tokens'],\n",
    "                                    systemInstructions=None,\n",
    "                                    max_retries=state['model']['max_retries'],\n",
    "                                    wait_time=state['model']['wait_time'])\n",
    "\n",
    "    # Outputs from the previous state\n",
    "    refined_sample_summarized_pnl_commentaries = state['results']['refine_old_summaries']\n",
    "\n",
    "    # Prompt\n",
    "    title_comment_template = \"For Buisness <BUIS>, on  <DATE>, driven by <NET>$  <FACTOR> <PROF_LOSS> to PL on <CUR> Currency on Portfolio <PF> and Desk <DSK>\"\n",
    "    user_prompt_list = [\n",
    "    \"You are a financial assistant. Your task is to generate structured queries from given templates to create financial summaries.\",\n",
    "    \n",
    "    f\"Here is an example pattern for financial summaries: {refined_sample_summarized_pnl_commentaries[0]}.\",\n",
    "    \n",
    "    f\"You are provided with a list of rule-based templates in the format List[{title_comment_template}]. Extract meaningful queries from these templates.\",\n",
    "    \n",
    "    \"\"\"Generate at least 15 diverse queries that can be used to generate sample financial summaries.\n",
    "    \n",
    "    - The queries should focus on aggregations such as min, max, mean, and sum, or retrieve the top 5 / bottom 5 entities.  \n",
    "    - Avoid queries that fetch all rows or list all entities without aggregation.  \n",
    "    - Do not create separate queries for different aggregations on the same entity; instead, combine them into a single query.  \n",
    "    - Dont ask for a particular value; instead, ask for a top k or bottom k value. Say, top 5 Business Units or bottom 5 Desks.\n",
    "    - The queries should be sufficient to address the financial summary patterns mentioned above.  \n",
    "    - Replace all field values with placeholders using the format <FIELD>. Do not include actual values.  \n",
    "    - Do not summarize the data; just generate structured queries.\"\"\",\n",
    "    \n",
    "    \"You must use the tool `FinancialQueries`. Your response must strictly follow the argument structure of `FinancialQueries`.\"\n",
    "    ]\n",
    "\n",
    "    # Generate queries\n",
    "    queries = fin_qry_engine(user_prompt_list)[0]['queries']\n",
    "    LOGGER.info(f\"State: {state['state']} | Generated {len(queries)} queries\")\n",
    "\n",
    "    # Save the result to state var and set the cache flag to True\n",
    "    state['results'][state['state']] = queries\n",
    "    state['cache_flag'][state['state']] = True\n",
    "\n",
    "    # Assign id to each query with sha hash\n",
    "    for query in state['results'][state['state']]:\n",
    "        query['id'] = hashlib.sha256(json.dumps(query).encode()).hexdigest()\n",
    "        query['flag'] = 'hot'\n",
    "\n",
    "    # Save the result to cache with the state name and {result} key\n",
    "    save_json_data(state['cache_location'][state['state']], {\"result\":state['results'][state['state']]})\n",
    "\n",
    "    LOGGER.info(f\"State: {state['state']} | Query generation completed, saved the result to cache and set the cache flag to True\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stat_query_agent(state: AgentState):\n",
    "    state['state'] = 'stat_query_generation'\n",
    "    LOGGER.info(f\"State: {state['state']} | Initializing the agent to refine old summaries\")\n",
    "\n",
    "    # Load the data from cache if the cache flag is set to True\n",
    "    cached_result = load_cached_results(state)\n",
    "    if cached_result:\n",
    "        return state\n",
    "    \n",
    "    ## It is not an AI task, it is a rule-based task. So, we can directly write the code here.\n",
    "\n",
    "    statistical_queries = [\n",
    "        \"What is average, max, min, varaince, sum of <NET> profit/loss?\",\n",
    "        \"What is average, max, min, varaince, sum of <FACTOR> profit/loss grouped by <BUIS>?\",\n",
    "        \"What is average, max, min, varaince, sum of <NET> profit/loss grouped by <CUR> currency?\",\n",
    "        \"What is average, max, min, varaince, sum of <NET> profit/loss grouped by top 5 <PF> portfolios?\",\n",
    "        \"What is average, max, min, varaince, sum of <NET> profit/loss grouped by bottom 5 <PF> portfolios?\",\n",
    "        \"What is average, max, min, varaince, sum of <NET> profit/loss grouped by top 5 <DSK> desks?\",\n",
    "        \"What is average, max, min, varaince, sum of <NET> profit/loss grouped by bottom 5 <DSK> desks?\",\n",
    "        \"What are the top currencies by average <NET> profit/loss?\",\n",
    "        \"What are the bottom currencies by average <NET> profit/loss?\",\n",
    "        \"What is the total count of transactions for each <FACTOR>?\",\n",
    "        \"What is the percentage contribution of each <FACTOR> to total profit/loss?\",\n",
    "        \"What is the trend of total <NET> profit/loss over time (daily, monthly, yearly)?\",\n",
    "        \"What is the moving average of <NET> profit/loss over the past 7 days?\",\n",
    "        \"What is the standard deviation of <NET> profit/loss grouped by <BUIS>?\",\n",
    "        \"What is the correlation between <FACTOR> and <NET> profit/loss?\",\n",
    "        \"What is the skewness and kurtosis of <NET> profit/loss distribution?\",\n",
    "        \"Which <PF> portfolios have the highest standard deviation in <NET> profit/loss?\",\n",
    "        \"Which <DSK> desks have the highest variance in <NET> profit/loss?\",\n",
    "        \"What is the probability distribution of <NET> profit/loss?\",\n",
    "        \"What is the cumulative sum of <NET> profit/loss over time?\",\n",
    "        \"Which <CUR> currency has the most volatile <NET> profit/loss?\",\n",
    "        \"What is the ratio of profitable to loss-making transactions per <FACTOR>?\",\n",
    "        \"Which <PF> portfolios have the most consistently positive (low variance) profits?\",\n",
    "        \"Which <FACTOR> contributes most to total profit/loss variance?\",\n",
    "        \"What is the ratio of profit to loss per <DSK> desk?\",\n",
    "        \"Which <CUR> currency contributes the most to total profit?\",\n",
    "        \"Which <FACTOR> has the highest frequency of losses?\"\n",
    "    ]\n",
    "    statistical_queries = [{\"query\": query} for query in statistical_queries]\n",
    "\n",
    "    # Save the result to state var and set the cache flag to True\n",
    "    state['results'][state['state']] = statistical_queries\n",
    "    state['cache_flag'][state['state']] = True\n",
    "\n",
    "    # Assign id to each query with sha hash\n",
    "    for query in state['results'][state['state']]:\n",
    "        query['id'] = hashlib.sha256(json.dumps(query).encode()).hexdigest()\n",
    "        query['flag'] = 'hot'\n",
    "        \n",
    "    # Save the result to cache with the state name and {result} key\n",
    "    save_json_data(state['cache_location'][state['state']], {\"result\":state['results'][state['state']]})\n",
    "\n",
    "    LOGGER.info(f\"State: {state['state']} | Query generation completed, saved the result to cache and set the cache flag to True\")\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_data(state: AgentState):\n",
    "    state['state'] = 'register_data'\n",
    "    LOGGER.info(f\"State: {state['state']} | Initializing the agent to register data\")\n",
    "\n",
    "    # It is a very naive implementation, we can directly write the code here.\n",
    "    rule_based_title_comment_data  = load_json_data(state['cache_location']['rule_based_title_comment_data'])\n",
    "    \n",
    "    global TITLE_DATA_INMEM_DB\n",
    "    TITLE_DATA_INMEM_DB = get_title_data_inmemory_db(rule_based_title_comment_data)\n",
    "\n",
    "    LOGGER.info(f\"State: {state['state']} | Data registration completed, saved the data to in-memory DB. Global variable TITLE_DATA_INMEM_DB is set\")\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql_script_agent(state: AgentState):\n",
    "    state['state'] = 'sql_script_generation'\n",
    "    LOGGER.info(f\"State: {state['state']} | Initializing the agent to generate SQL script\")\n",
    "\n",
    "    # Load the data from cache if the cache flag is set to True\n",
    "    cached_result = load_cached_results(state)\n",
    "\n",
    "    # We avoid total cache here as the data. We selectively load the cache for the title_data table\n",
    "    # if cached_result:\n",
    "    #     return state\n",
    "\n",
    "    # Initialize the model\n",
    "    sql_script_engine =  GeminiJsonEngine(\n",
    "                                    model_name=state['model']['model_name'],\n",
    "                                    basemodel=SQLScript,\n",
    "                                    temperature=state['model']['temperature'],\n",
    "                                    max_output_tokens=state['model']['max_output_tokens'],\n",
    "                                    systemInstructions=\"You are an expert financial bot. You will be given a table and you need to generate a SQL script to query the data from the table. \",\n",
    "                                    max_retries=state['model']['max_retries'],\n",
    "                                    wait_time=state['model']['wait_time'])\n",
    "\n",
    "    # Previous state outputs\n",
    "    subj_queries = state['results']['subj_query_generation']\n",
    "    stat_queries = state['results']['stat_query_generation']\n",
    "    all_queries = subj_queries + stat_queries\n",
    "\n",
    "    global TITLE_DATA_INMEM_DB\n",
    "    # Head of the table\n",
    "    _rule_based_title_comment_data_cols,_rule_based_title_comment_data_head = TITLE_DATA_INMEM_DB.query_data(\"SELECT * FROM title_data LIMIT 5\")\n",
    "    head = pd.DataFrame(_rule_based_title_comment_data_head, columns=_rule_based_title_comment_data_cols).drop(columns=['id','COMMENT']).head()\n",
    "\n",
    "    sql_scripts = []\n",
    "    for i, query in enumerate(all_queries):\n",
    "        sql_script = None \n",
    "        if query['flag']=='cold' and cached_result['results'][state['state']]:\n",
    "            for k in cached_result['results'][state['state']] :\n",
    "                if k['id']==query['id']:\n",
    "                    sql_script = k\n",
    "                    sql_scripts.append(sql_script)\n",
    "                    LOGGER.info(f\"State: {state['state']} | {i}/{len(all_queries)} SQL script loaded from cache for the query: {query['query'][:20]} ... to {sql_script['sql_script'][:20]} ...\")\n",
    "                    break\n",
    "    \n",
    "        if sql_script is None:\n",
    "            user_sql_prompt = [\n",
    "                f\"You are a SQL expert. Your task is to write a SQL script to query data from the given table. Note: you are generating a SQL script for SQLLite's python library. You must be careful while writing complex queries as it is very sensitive.\",\n",
    "                f\"Library specific notes: STDDEV is not supported in SQLLite. You can use AVG and SUM to calculate the standard deviation.\",\n",
    "                f\"Here is the schema of the table `title_data`: {TITLE_DATA_INMEM_DB.metadata.tables}\",\n",
    "                f\"Here is the are the first few rows of the table `title_data`: {head}\",\n",
    "                f\"User is trying to answer the following query: {query['query']}\",\n",
    "                f\"Write a SQL script to answer the query using the tool `SQLScript`. Your answer must follow the argument strucure of the tool `SQLScript`. You are encouraged to use compound and complex SQL queries to answer the query.\"\n",
    "            ]\n",
    "            sql_script = sql_script_engine(user_sql_prompt)[0]\n",
    "            sql_scripts.append(sql_script)\n",
    "            LOGGER.info(f\"State: {state['state']} | {i}/{len(all_queries)} SQL script generated for the query: {query['query'][:20]} ... to {sql_script['sql_script'][:20]} ...\")\n",
    "            query['flag']='cold'\n",
    "            LOGGER.info(f\"State: {state['state']} | {i}/{len(all_queries)} Query flag changed to cold\")\n",
    "\n",
    "    \n",
    "    # Save the result to state var and set the cache flag to True\n",
    "    state['results'][state['state']] = sql_scripts\n",
    "    state['cache_flag'][state['state']] = True\n",
    "\n",
    "    # Assign id to each query with the same hash as the query\n",
    "    for raw_query, sql_script in zip(all_queries, state['results'][state['state']]):\n",
    "        sql_script['id'] = raw_query['id']\n",
    "        sql_script['flag'] = raw_query['flag']\n",
    "\n",
    "    # Save the result to cache with the state name and {result} key\n",
    "    save_json_data(state['cache_location'][state['state']], {\"result\":state['results'][state['state']]})\n",
    "    LOGGER.info(f\"State: {state['state']} | SQL script generation completed, saved the result to cache and set the cache flag to True\")\n",
    "\n",
    "    # Save the previous state results with proper hot/cold flag\n",
    "    save_json_data(state['cache_location']['subj_query_generation'], {\"result\":subj_queries})\n",
    "    save_json_data(state['cache_location']['stat_query_generation'], {\"result\":stat_queries})\n",
    "    LOGGER.info(f\"State: {state['state']} | Saved the previous state subj_query_generation and stat_query_generation results to cache with proper all cold flag\")\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_result_agent(state:AgentState):\n",
    "    state['state'] = 'sql_result'\n",
    "    LOGGER.info(f\"State: {state['state']} | Initializing the agent to generate SQL result\")\n",
    "\n",
    "    #### TODO: Implement Selective Caching for the SQL result. We are currently avoiding the cache for the SQL result as it is not that expensive to run the SQL queries again.\n",
    "    # Load the data from cache if the cache flag is set to True\n",
    "    # cached_result = load_cached_results(state)\n",
    "    # if cached_result:\n",
    "    #     return state\n",
    "\n",
    "    global TITLE_DATA_INMEM_DB\n",
    "    \n",
    "    # Previous state outputs\n",
    "    sql_scripts = state['results']['sql_script_generation']\n",
    "\n",
    "    # Execute the SQL scripts\n",
    "    sql_results = []\n",
    "    pass_count = 0\n",
    "    fail_count = 0\n",
    "    overlength_count = 0\n",
    "    for i, sql_script in enumerate(sql_scripts):\n",
    "        try:\n",
    "            columns, data = TITLE_DATA_INMEM_DB.query_data(sql_script['sql_script'])\n",
    "            sql_results.append({\n",
    "                \"id\": sql_script['id'],\n",
    "                \"columns\": columns,\n",
    "                \"data\": data,\n",
    "                \"status\": \"success\",\n",
    "                \"description\": sql_script['description'],\n",
    "                \"sql_script\": sql_script['sql_script']\n",
    "            })\n",
    "            if len(data) < 20:\n",
    "                LOGGER.info(f\"State: {state['state']} | {i}/{len(sql_scripts)} SQL script executed, {len(data)} rows returned\")\n",
    "                pass_count += 1\n",
    "            else:\n",
    "                LOGGER.warning(f\"State: {state['state']} | {i}/{len(sql_scripts)} SQL script executed, {len(data)} rows returned. Too many rows returned, consider refining the query\")\n",
    "                sql_results[-1]['status'] = \"overlength\"\n",
    "                overlength_count += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            LOGGER.error(f\"State: {state['state']} | {i}/{len(sql_scripts)} SQL script execution failed: {str(e)}. Skipping the query\")\n",
    "            sql_results.append({\n",
    "                \"id\": sql_script['id'],\n",
    "                \"columns\": [],\n",
    "                \"data\": [],\n",
    "                \"status\": \"failed\",\n",
    "                \"description\": sql_script['description'],\n",
    "                \"sql_script\": sql_script['sql_script']\n",
    "            })\n",
    "            fail_count += 1\n",
    "\n",
    "    LOGGER.info(f\"State: {state['state']} | SQL script execution completed, {pass_count} passed, {fail_count} failed, {overlength_count} overlength\")\n",
    "\n",
    "    # Save the result to state var and set the cache flag to True\n",
    "    state['results'][state['state']] = sql_results\n",
    "    state['cache_flag'][state['state']] = True\n",
    "\n",
    "    # Save the result to cache with the state name and {result} key\n",
    "    save_json_data(state['cache_location'][state['state']], {\"result\":state['results'][state['state']]})\n",
    "\n",
    "    LOGGER.info(f\"State: {state['state']} | SQL result generation completed, saved the result to cache and set the cache flag to True\")\n",
    "\n",
    "    return state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bucket_query_agent(state: AgentState):\n",
    "    state['state'] = 'bucket_query_generation'\n",
    "    LOGGER.info(f\"State: {state['state']} | Initializing the agent to generate bucket queries\")\n",
    "\n",
    "    # It is not an AI task, it is a rule-based task. So, we can directly write the code here.\n",
    "\n",
    "    # Load previous state outputs\n",
    "    old_summary = state['results']['refine_old_summaries'][0]\n",
    "    subj_results = state['results']['subj_query_generation']\n",
    "    stat_results = state['results']['stat_query_generation']\n",
    "    sql_results = [result for result in state['results']['sql_result'] if result['status'] == 'success']\n",
    "\n",
    "    # Subj IDs and  Stat IDs\n",
    "    subj_ids = [query['id'] for query in subj_results]\n",
    "    stat_ids = [query['id'] for query in stat_results]\n",
    "\n",
    "    # Filter SQL results with subj and stat IDs\n",
    "    sql_subj_results = [result for result in sql_results if result['id'] in subj_ids]\n",
    "    sql_stat_results = [result for result in sql_results if result['id'] in stat_ids]\n",
    "\n",
    "    # Bucket queries\n",
    "    sql_subj_result_qa_s = \"\\n\".join([f\"Q{i}. {result['description']}:\\n{pd.DataFrame(result['data'], columns=result['columns']).head()}\" for i, result in enumerate(sql_subj_results)])\n",
    "    sql_stat_result_qa_s = \"\\n\".join([f\"Q{i}. {result['description']}:\\n{pd.DataFrame(result['data'], columns=result['columns']).head()}\" for i, result in enumerate(sql_stat_results)])\n",
    "\n",
    "    \n",
    "    prompts = [[\n",
    "        f\"You are financial expert. Your task is to provide a DETAILED and SOPHISTICATED financial summary over P&L Trend and other financial metrics. You are provided with some structured questions and their answers. You need to generate the summary from the insights provided in the answers.\",\n",
    "        f\"The meaning for the columns are as follows: BUIS means Business Unit, DATE means Day of calcualtion, NET means Net Profit/Loss, Factor such as IRDelta, IRGamma, FXDelta etc., PROF_LOSS means Profit or Loss, CUR means Currency, PF means Portfolio, DSK means Desk.\",\n",
    "        f\"Here is a sample summary for reference (Just follow the pattern, not the exact values): {old_summary}\",\n",
    "        f\"Here are the structured questions and their answers: {qa}\",\n",
    "        f\"Generate a detailed financial summary based on the insights provided in the answers.\"\n",
    "    ] for qa in [sql_subj_result_qa_s, sql_stat_result_qa_s]]\n",
    "\n",
    "\n",
    "    # Update the state\n",
    "    state['results'][state['state']] = prompts\n",
    "\n",
    "    LOGGER.info(f\"State: {state['state']} | Bucket queries generated\")\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_result(state: AgentState):\n",
    "    state['state'] = 'final_result'\n",
    "    LOGGER.info(f\"State: {state['state']} | Initializing the agent to generate final result\")\n",
    "\n",
    "    # Load the data from cache if the cache flag is set to True\n",
    "    cached_result = load_cached_results(state)\n",
    "    if cached_result:\n",
    "        return state\n",
    "\n",
    "    # Initialize the model\n",
    "    gemini_simple_chat_engine = GeminiSimpleChatEngine(model_name=state['model']['model_name'], \n",
    "                                                   temperature=state['model']['temperature'],\n",
    "                                                   max_output_tokens=1024,\n",
    "                                                   systemInstructions=None,\n",
    "                                                   max_retries=state['model']['max_retries'],\n",
    "                                                   wait_time=state['model']['wait_time'])\n",
    "\n",
    "    # Previous state outputs\n",
    "    bucket_queries = state['results']['bucket_query_generation']\n",
    "\n",
    "    # Generate the final result\n",
    "    final_results = []\n",
    "    for i, bucket_query in enumerate(bucket_queries):\n",
    "        final_result = gemini_simple_chat_engine(bucket_query)\n",
    "        final_results.append(final_result)\n",
    "        LOGGER.info(f\"State: {state['state']} | {i}/{len(bucket_queries)} Final result generated from the bucket query. {final_result[:30]}...\")\n",
    "\n",
    "    # Save the result to state var and set the cache flag to True\n",
    "    state['results'][state['state']] = final_results\n",
    "    state['cache_flag'][state['state']] = True\n",
    "\n",
    "    # Save the result to cache with the state name and {result} key\n",
    "    save_json_data(state['cache_location'][state['state']], {\"result\":state['results'][state['state']]})\n",
    "\n",
    "\n",
    "    LOGGER.info(f\"State: {state['state']} | Final result generation completed, saved the result to cache and set the cache flag to True\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAgent:\n",
    "    def __init__(self, thread_id=None):\n",
    "        self.config = None\n",
    "        self.app = None\n",
    "        self.build(thread_id)\n",
    "\n",
    "    def build(self, thread_id):\n",
    "        workflow = StateGraph(AgentState)\n",
    "\n",
    "        # Nodes\n",
    "        workflow.add_node('start', start_agent)\n",
    "        workflow.add_node('end', end_agent)\n",
    "        workflow.add_node('refine_old_summaries', refine_old_summary_agent)\n",
    "        workflow.add_node('generate_subj_queries', generate_subj_query_agent)\n",
    "        workflow.add_node('generate_stat_queries', generate_stat_query_agent)\n",
    "        workflow.add_node('register_data', register_data)\n",
    "        workflow.add_node('sql_script_generation', generate_sql_script_agent)\n",
    "        workflow.add_node('sql_result_generation', sql_result_agent)\n",
    "        workflow.add_node('bucket_query_generation', generate_bucket_query_agent)\n",
    "        workflow.add_node('final_result', generate_final_result)\n",
    "\n",
    "        # Edges\n",
    "        workflow.add_edge('start', 'refine_old_summaries')\n",
    "        workflow.add_edge('refine_old_summaries', 'generate_subj_queries')\n",
    "        workflow.add_edge('generate_subj_queries', 'generate_stat_queries')\n",
    "        workflow.add_edge('generate_stat_queries', 'register_data')\n",
    "        workflow.add_edge('register_data', 'sql_script_generation')\n",
    "        workflow.add_edge('sql_script_generation', 'sql_result_generation')\n",
    "        workflow.add_edge('sql_result_generation', 'bucket_query_generation')\n",
    "        workflow.add_edge('bucket_query_generation', 'final_result')\n",
    "        workflow.add_edge('final_result', 'end')\n",
    "\n",
    "        # Compile\n",
    "        workflow.set_entry_point('start')\n",
    "        memory = MemorySaver()\n",
    "        self.app = workflow.compile(checkpointer=memory)\n",
    "        self.config = {\"configurable\":{\"thread_id\":str(thread_id)}}\n",
    "\n",
    "    def get_recent_state_snap(self):\n",
    "        snap = self.app.get_state(self.config).values.copy()\n",
    "        return snap\n",
    "    \n",
    "    def get_graph(self):\n",
    "        graph = self.app.get_graph(xray=True)\n",
    "        return graph\n",
    "    \n",
    "    def continue_flow(self, state):\n",
    "        self.app.invoke(state, config=self.config)\n",
    "        save_json_data(state['cache_location']['state_config'], state)\n",
    "        return self.get_recent_state_snap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_AGENT = MyAgent(thread_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MY_AGENT.get_recent_state_snap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       +-----------+         \n",
      "       | __start__ |         \n",
      "       +-----------+         \n",
      "              *              \n",
      "              *              \n",
      "              *              \n",
      "         +-------+           \n",
      "         | start |           \n",
      "         +-------+           \n",
      "              *              \n",
      "              *              \n",
      "              *              \n",
      "  +----------------------+   \n",
      "  | refine_old_summaries |   \n",
      "  +----------------------+   \n",
      "              *              \n",
      "              *              \n",
      "              *              \n",
      " +-----------------------+   \n",
      " | generate_subj_queries |   \n",
      " +-----------------------+   \n",
      "              *              \n",
      "              *              \n",
      "              *              \n",
      " +-----------------------+   \n",
      " | generate_stat_queries |   \n",
      " +-----------------------+   \n",
      "              *              \n",
      "              *              \n",
      "              *              \n",
      "     +---------------+       \n",
      "     | register_data |       \n",
      "     +---------------+       \n",
      "              *              \n",
      "              *              \n",
      "              *              \n",
      " +-----------------------+   \n",
      " | sql_script_generation |   \n",
      " +-----------------------+   \n",
      "              *              \n",
      "              *              \n",
      "              *              \n",
      " +-----------------------+   \n",
      " | sql_result_generation |   \n",
      " +-----------------------+   \n",
      "              *              \n",
      "              *              \n",
      "              *              \n",
      "+-------------------------+  \n",
      "| bucket_query_generation |  \n",
      "+-------------------------+  \n",
      "              *              \n",
      "              *              \n",
      "              *              \n",
      "      +--------------+       \n",
      "      | final_result |       \n",
      "      +--------------+       \n",
      "              *              \n",
      "              *              \n",
      "              *              \n",
      "          +-----+            \n",
      "          | end |            \n",
      "          +-----+            \n"
     ]
    }
   ],
   "source": [
    "graph = MY_AGENT.get_graph()\n",
    "print(graph.draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m2025-03-10 22:17:05,992 - INFO ==> Starting the agent-assist\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:17:05,993 - INFO ==> State: refine_old_summaries | Initializing the agent to refine old summaries\u001b[0m\n",
      "\u001b[1;36m2025-03-10 22:17:06,215 - DEBUG ==> Initialized GeminiModel with model gemini-2.0-flash-001 , project hackathon0-project, location us-central1\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:17:06,217 - INFO ==> State: refine_old_summaries | Loaded the sample data, 3 old summaries found\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:17:10,636 - INFO ==> State: refine_old_summaries | Summary refined , \n",
      "Derivatives +€2m: Down 92% vs... to Derivatives performance reache...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:17:15,348 - INFO ==> State: refine_old_summaries | Summary refined , \n",
      "Derivatives +€26m: Up 18% vs ... to Derivatives revenue reached +€...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:17:19,855 - INFO ==> State: refine_old_summaries | Summary refined , \n",
      "• Forwards €12m: Revenues up ... to The financial report indicates...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:17:19,856 - INFO ==> State: refine_old_summaries | Refinement of old summaries completed, saved the result to cache and set the cache flag to True\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:17:19,858 - INFO ==> State: subj_query_generation | Initializing the agent to refine old summaries\u001b[0m\n",
      "\u001b[1;36m2025-03-10 22:17:20,091 - DEBUG ==> Initialized GeminiModel with model gemini-2.0-flash-001 , project hackathon0-project, location us-central1\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:17:24,256 - INFO ==> State: subj_query_generation | Generated 15 queries\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:17:24,260 - INFO ==> State: subj_query_generation | Query generation completed, saved the result to cache and set the cache flag to True\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:17:24,263 - INFO ==> State: stat_query_generation | Initializing the agent to refine old summaries\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:17:24,266 - INFO ==> State: stat_query_generation | Query generation completed, saved the result to cache and set the cache flag to True\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:17:24,267 - INFO ==> State: register_data | Initializing the agent to register data\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:17:24,391 - INFO ==> State: register_data | Data registration completed, saved the data to in-memory DB. Global variable TITLE_DATA_INMEM_DB is set\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:17:24,392 - INFO ==> State: sql_script_generation | Initializing the agent to generate SQL script\u001b[0m\n",
      "\u001b[1;36m2025-03-10 22:17:24,599 - DEBUG ==> Initialized GeminiModel with model gemini-2.0-flash-001 , project hackathon0-project, location us-central1\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:17:27,124 - INFO ==> State: sql_script_generation | 0/42 SQL script generated for the query: What are the <FACTOR ... to SELECT FACTOR FROM t ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:17:27,125 - INFO ==> State: sql_script_generation | 0/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:17:28,968 - WARNING ==> Rate limit hit. Retrying in 30 seconds... (Attempt 1/5)\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:17:59,995 - INFO ==> State: sql_script_generation | 1/42 SQL script generated for the query: Which <CUR> currenci ... to SELECT CUR, PF FROM  ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:17:59,997 - INFO ==> State: sql_script_generation | 1/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:18:02,555 - INFO ==> State: sql_script_generation | 2/42 SQL script generated for the query: What is the average  ... to SELECT BUIS, DATE, A ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:18:02,557 - INFO ==> State: sql_script_generation | 2/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:18:04,400 - WARNING ==> Rate limit hit. Retrying in 30 seconds... (Attempt 1/5)\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:18:34,915 - WARNING ==> Rate limit hit. Retrying in 30 seconds... (Attempt 2/5)\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:19:07,378 - INFO ==> State: sql_script_generation | 3/42 SQL script generated for the query: List the top 5 <BUIS ... to SELECT BUIS FROM tit ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:19:07,380 - INFO ==> State: sql_script_generation | 3/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:19:09,733 - INFO ==> State: sql_script_generation | 4/42 SQL script generated for the query: List the bottom 5 <B ... to SELECT BUIS FROM tit ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:19:09,735 - INFO ==> State: sql_script_generation | 4/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:19:11,575 - WARNING ==> Rate limit hit. Retrying in 30 seconds... (Attempt 1/5)\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:19:43,424 - WARNING ==> Rate limit hit. Retrying in 30 seconds... (Attempt 2/5)\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:20:15,781 - INFO ==> State: sql_script_generation | 5/42 SQL script generated for the query: What is the sum of < ... to SELECT PF, SUM(NET)  ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:20:15,783 - INFO ==> State: sql_script_generation | 5/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:20:18,137 - INFO ==> State: sql_script_generation | 6/42 SQL script generated for the query: What is the maximum  ... to SELECT BUIS, DATE, m ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:20:18,138 - INFO ==> State: sql_script_generation | 6/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:20:19,980 - WARNING ==> Rate limit hit. Retrying in 30 seconds... (Attempt 1/5)\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:20:51,317 - INFO ==> State: sql_script_generation | 7/42 SQL script generated for the query: What is the minimum  ... to SELECT BUIS, DATE, m ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:20:51,318 - INFO ==> State: sql_script_generation | 7/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:20:53,670 - INFO ==> State: sql_script_generation | 8/42 SQL script generated for the query: What are the top 5 < ... to SELECT DSK FROM titl ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:20:53,672 - INFO ==> State: sql_script_generation | 8/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:20:56,026 - INFO ==> State: sql_script_generation | 9/42 SQL script generated for the query: What are the bottom  ... to SELECT DSK FROM titl ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:20:56,028 - INFO ==> State: sql_script_generation | 9/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:20:57,869 - WARNING ==> Rate limit hit. Retrying in 30 seconds... (Attempt 1/5)\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:21:29,733 - WARNING ==> Rate limit hit. Retrying in 30 seconds... (Attempt 2/5)\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:22:02,199 - INFO ==> State: sql_script_generation | 10/42 SQL script generated for the query: What is the average  ... to SELECT CUR, AVG(NET) ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:22:02,201 - INFO ==> State: sql_script_generation | 10/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:22:04,552 - INFO ==> State: sql_script_generation | 11/42 SQL script generated for the query: What is the sum of < ... to SELECT FACTOR, SUM(N ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:22:04,553 - INFO ==> State: sql_script_generation | 11/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:22:06,396 - WARNING ==> Rate limit hit. Retrying in 30 seconds... (Attempt 1/5)\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:22:38,245 - WARNING ==> Rate limit hit. Retrying in 30 seconds... (Attempt 2/5)\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:23:09,583 - INFO ==> State: sql_script_generation | 12/42 SQL script generated for the query: What are the top 5 < ... to SELECT PF FROM title ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:23:09,585 - INFO ==> State: sql_script_generation | 12/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:23:11,876 - INFO ==> State: sql_script_generation | 13/42 SQL script generated for the query: What are the bottom  ... to SELECT PF FROM title ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:23:11,879 - INFO ==> State: sql_script_generation | 13/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:23:13,779 - WARNING ==> Rate limit hit. Retrying in 30 seconds... (Attempt 1/5)\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:23:46,453 - INFO ==> State: sql_script_generation | 14/42 SQL script generated for the query: What is the mean <NE ... to SELECT BUIS, DATE, A ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:23:46,455 - INFO ==> State: sql_script_generation | 14/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:23:48,969 - INFO ==> State: sql_script_generation | 15/42 SQL script generated for the query: What is average, max ... to SELECT AVG(NET), MAX ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:23:48,970 - INFO ==> State: sql_script_generation | 15/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:23:51,568 - INFO ==> State: sql_script_generation | 16/42 SQL script generated for the query: What is average, max ... to SELECT BUIS, AVG(CAS ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:23:51,571 - INFO ==> State: sql_script_generation | 16/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:23:54,185 - INFO ==> State: sql_script_generation | 17/42 SQL script generated for the query: What is average, max ... to SELECT CUR, AVG(NET) ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:23:54,186 - INFO ==> State: sql_script_generation | 17/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:23:56,071 - WARNING ==> Rate limit hit. Retrying in 30 seconds... (Attempt 1/5)\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:24:27,919 - WARNING ==> Rate limit hit. Retrying in 30 seconds... (Attempt 2/5)\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:25:01,304 - INFO ==> State: sql_script_generation | 18/42 SQL script generated for the query: What is average, max ... to WITH PortfolioAverag ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:25:01,306 - INFO ==> State: sql_script_generation | 18/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:25:03,966 - INFO ==> State: sql_script_generation | 19/42 SQL script generated for the query: What is average, max ... to SELECT PF, AVG(NET), ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:25:03,967 - INFO ==> State: sql_script_generation | 19/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:25:05,911 - WARNING ==> Rate limit hit. Retrying in 30 seconds... (Attempt 1/5)\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:25:37,759 - WARNING ==> Rate limit hit. Retrying in 30 seconds... (Attempt 2/5)\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:26:11,247 - INFO ==> State: sql_script_generation | 20/42 SQL script generated for the query: What is average, max ... to WITH DeskSummary AS  ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:26:11,248 - INFO ==> State: sql_script_generation | 20/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:26:14,110 - INFO ==> State: sql_script_generation | 21/42 SQL script generated for the query: What is average, max ... to SELECT AVG(NET), MAX ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:26:14,111 - INFO ==> State: sql_script_generation | 21/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:26:16,471 - INFO ==> State: sql_script_generation | 22/42 SQL script generated for the query: What are the top cur ... to SELECT CUR, AVG(NET) ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:26:16,474 - INFO ==> State: sql_script_generation | 22/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:26:18,310 - WARNING ==> Rate limit hit. Retrying in 30 seconds... (Attempt 1/5)\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:26:50,773 - INFO ==> State: sql_script_generation | 23/42 SQL script generated for the query: What are the bottom  ... to SELECT CUR, AVG(NET) ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:26:50,775 - INFO ==> State: sql_script_generation | 23/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:26:53,229 - INFO ==> State: sql_script_generation | 24/42 SQL script generated for the query: What is the total co ... to SELECT FACTOR, count ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:26:53,231 - INFO ==> State: sql_script_generation | 24/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:26:55,073 - WARNING ==> Rate limit hit. Retrying in 30 seconds... (Attempt 1/5)\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:27:27,025 - WARNING ==> Rate limit hit. Retrying in 30 seconds... (Attempt 2/5)\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:27:59,485 - INFO ==> State: sql_script_generation | 25/42 SQL script generated for the query: What is the percenta ... to SELECT FACTOR, (SUM( ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:27:59,486 - INFO ==> State: sql_script_generation | 25/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:28:01,840 - INFO ==> State: sql_script_generation | 26/42 SQL script generated for the query: What is the trend of ... to SELECT DATE, sum(NET ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:28:01,842 - INFO ==> State: sql_script_generation | 26/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:28:03,683 - WARNING ==> Rate limit hit. Retrying in 30 seconds... (Attempt 1/5)\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:28:35,533 - WARNING ==> Rate limit hit. Retrying in 30 seconds... (Attempt 2/5)\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:29:08,096 - INFO ==> State: sql_script_generation | 27/42 SQL script generated for the query: What is the moving a ... to SELECT DATE, AVG(NET ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:29:08,097 - INFO ==> State: sql_script_generation | 27/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:29:10,655 - INFO ==> State: sql_script_generation | 28/42 SQL script generated for the query: What is the standard ... to SELECT BUIS, SUM(NET ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:29:10,655 - INFO ==> State: sql_script_generation | 28/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:29:13,215 - INFO ==> State: sql_script_generation | 29/42 SQL script generated for the query: What is the correlat ... to SELECT corr(CASE WHE ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:29:13,217 - INFO ==> State: sql_script_generation | 29/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:29:17,416 - INFO ==> State: sql_script_generation | 30/42 SQL script generated for the query: What is the skewness ... to \n",
      "WITH\n",
      "  Data AS (\n",
      "   ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:29:17,417 - INFO ==> State: sql_script_generation | 30/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:29:19,257 - WARNING ==> Rate limit hit. Retrying in 30 seconds... (Attempt 1/5)\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:29:51,822 - INFO ==> State: sql_script_generation | 31/42 SQL script generated for the query: Which <PF> portfolio ... to SELECT PF, SUM(NET * ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:29:51,824 - INFO ==> State: sql_script_generation | 31/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:29:54,384 - INFO ==> State: sql_script_generation | 32/42 SQL script generated for the query: Which <DSK> desks ha ... to SELECT DSK, SUM(NET  ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:29:54,385 - INFO ==> State: sql_script_generation | 32/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:29:56,942 - INFO ==> State: sql_script_generation | 33/42 SQL script generated for the query: What is the probabil ... to SELECT NET, PROF_LOS ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:29:56,944 - INFO ==> State: sql_script_generation | 33/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:29:58,784 - WARNING ==> Rate limit hit. Retrying in 30 seconds... (Attempt 1/5)\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:30:30,634 - WARNING ==> Rate limit hit. Retrying in 30 seconds... (Attempt 2/5)\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:31:02,992 - INFO ==> State: sql_script_generation | 34/42 SQL script generated for the query: What is the cumulati ... to SELECT DATE, SUM(NET ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:31:02,994 - INFO ==> State: sql_script_generation | 34/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:31:05,349 - INFO ==> State: sql_script_generation | 35/42 SQL script generated for the query: Which <CUR> currency ... to SELECT CUR FROM titl ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:31:05,351 - INFO ==> State: sql_script_generation | 35/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:31:06,476 - INFO ==> State: sql_script_generation | 36/42 SQL script generated for the query: What is the ratio of ... to SELECT FACTOR, CAST( ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:31:06,478 - INFO ==> State: sql_script_generation | 36/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:31:09,648 - INFO ==> State: sql_script_generation | 37/42 SQL script generated for the query: Which <PF> portfolio ... to SELECT PF, AVG(CAST( ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:31:09,650 - INFO ==> State: sql_script_generation | 37/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:31:11,478 - WARNING ==> Rate limit hit. Retrying in 30 seconds... (Attempt 1/5)\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:31:43,338 - WARNING ==> Rate limit hit. Retrying in 30 seconds... (Attempt 2/5)\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:15,808 - INFO ==> State: sql_script_generation | 38/42 SQL script generated for the query: Which <FACTOR> contr ... to SELECT FACTOR, SUM(P ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:15,810 - INFO ==> State: sql_script_generation | 38/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:18,358 - INFO ==> State: sql_script_generation | 39/42 SQL script generated for the query: What is the ratio of ... to SELECT DSK, SUM(CASE ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:18,359 - INFO ==> State: sql_script_generation | 39/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:20,819 - INFO ==> State: sql_script_generation | 40/42 SQL script generated for the query: Which <CUR> currency ... to SELECT CUR, SUM(PROF ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:20,820 - INFO ==> State: sql_script_generation | 40/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:32:22,660 - WARNING ==> Rate limit hit. Retrying in 30 seconds... (Attempt 1/5)\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:53,998 - INFO ==> State: sql_script_generation | 41/42 SQL script generated for the query: Which <FACTOR> has t ... to SELECT FACTOR FROM t ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,000 - INFO ==> State: sql_script_generation | 41/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,005 - INFO ==> State: sql_script_generation | SQL script generation completed, saved the result to cache and set the cache flag to True\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,008 - INFO ==> State: sql_script_generation | Saved the previous state subj_query_generation and stat_query_generation results to cache with proper all cold flag\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,011 - INFO ==> State: sql_result | Initializing the agent to generate SQL result\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,013 - INFO ==> State: sql_result | 0/42 SQL script executed, 1 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,015 - INFO ==> State: sql_result | 1/42 SQL script executed, 10 rows returned\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:32:54,018 - WARNING ==> State: sql_result | 2/42 SQL script executed, 562 rows returned. Too many rows returned, consider refining the query\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,019 - INFO ==> State: sql_result | 3/42 SQL script executed, 5 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,020 - INFO ==> State: sql_result | 4/42 SQL script executed, 5 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,021 - INFO ==> State: sql_result | 5/42 SQL script executed, 3 rows returned\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:32:54,023 - WARNING ==> State: sql_result | 6/42 SQL script executed, 562 rows returned. Too many rows returned, consider refining the query\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:32:54,024 - WARNING ==> State: sql_result | 7/42 SQL script executed, 404 rows returned. Too many rows returned, consider refining the query\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,025 - INFO ==> State: sql_result | 8/42 SQL script executed, 5 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,026 - INFO ==> State: sql_result | 9/42 SQL script executed, 5 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,027 - INFO ==> State: sql_result | 10/42 SQL script executed, 7 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,028 - INFO ==> State: sql_result | 11/42 SQL script executed, 6 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,029 - INFO ==> State: sql_result | 12/42 SQL script executed, 5 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,029 - INFO ==> State: sql_result | 13/42 SQL script executed, 5 rows returned\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:32:54,031 - WARNING ==> State: sql_result | 14/42 SQL script executed, 562 rows returned. Too many rows returned, consider refining the query\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,032 - INFO ==> State: sql_result | 15/42 SQL script executed, 1 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,033 - INFO ==> State: sql_result | 16/42 SQL script executed, 2 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,034 - INFO ==> State: sql_result | 17/42 SQL script executed, 7 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,036 - INFO ==> State: sql_result | 18/42 SQL script executed, 3 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,037 - INFO ==> State: sql_result | 19/42 SQL script executed, 3 rows returned\u001b[0m\n",
      "\u001b[1;31m2025-03-10 22:32:54,037 - ERROR ==> State: sql_result | 20/42 SQL script execution failed: (sqlite3.OperationalError) ambiguous column name: DSK\n",
      "[SQL: WITH DeskSummary AS (SELECT DSK, AVG(NET) AS avg_net, MAX(NET) AS max_net, MIN(NET) AS min_net, SUM(NET) AS sum_net, COUNT(NET) AS count_net FROM title_data GROUP BY DSK ORDER BY SUM(NET) DESC LIMIT 5) SELECT DSK, avg_net, max_net, min_net, sum_net, count_net, SUM((title_data.NET - DeskSummary.avg_net) * (title_data.NET - DeskSummary.avg_net)) / DeskSummary.count_net AS variance FROM title_data JOIN DeskSummary ON title_data.DSK = DeskSummary.DSK GROUP BY DSK, avg_net, max_net, min_net, sum_net, count_net ORDER BY sum_net DESC]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8). Skipping the query\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,039 - INFO ==> State: sql_result | 21/42 SQL script executed, 3 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,040 - INFO ==> State: sql_result | 22/42 SQL script executed, 7 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,040 - INFO ==> State: sql_result | 23/42 SQL script executed, 5 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,041 - INFO ==> State: sql_result | 24/42 SQL script executed, 6 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,042 - INFO ==> State: sql_result | 25/42 SQL script executed, 6 rows returned\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:32:54,043 - WARNING ==> State: sql_result | 26/42 SQL script executed, 281 rows returned. Too many rows returned, consider refining the query\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:32:54,044 - WARNING ==> State: sql_result | 27/42 SQL script executed, 281 rows returned. Too many rows returned, consider refining the query\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,045 - INFO ==> State: sql_result | 28/42 SQL script executed, 2 rows returned\u001b[0m\n",
      "\u001b[1;31m2025-03-10 22:32:54,045 - ERROR ==> State: sql_result | 29/42 SQL script execution failed: (sqlite3.OperationalError) no such function: corr\n",
      "[SQL: SELECT corr(CASE WHEN FACTOR = 'BondBasis' THEN 1 WHEN FACTOR = 'FXDelta' THEN 2 WHEN FACTOR = 'IRDelta' THEN 3 ELSE 0 END, CAST(NET AS REAL)) FROM title_data]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8). Skipping the query\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,047 - INFO ==> State: sql_result | 30/42 SQL script executed, 1 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,047 - INFO ==> State: sql_result | 31/42 SQL script executed, 3 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,048 - INFO ==> State: sql_result | 32/42 SQL script executed, 3 rows returned\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:32:54,050 - WARNING ==> State: sql_result | 33/42 SQL script executed, 1103 rows returned. Too many rows returned, consider refining the query\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:32:54,052 - WARNING ==> State: sql_result | 34/42 SQL script executed, 1103 rows returned. Too many rows returned, consider refining the query\u001b[0m\n",
      "\u001b[1;31m2025-03-10 22:32:54,053 - ERROR ==> State: sql_result | 35/42 SQL script execution failed: (sqlite3.OperationalError) misuse of aggregate function AVG()\n",
      "[SQL: SELECT CUR FROM title_data GROUP BY CUR ORDER BY SUM((NET - AVG(NET)) * (NET - AVG(NET))) DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8). Skipping the query\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,053 - INFO ==> State: sql_result | 36/42 SQL script executed, 6 rows returned\u001b[0m\n",
      "\u001b[1;31m2025-03-10 22:32:54,054 - ERROR ==> State: sql_result | 37/42 SQL script execution failed: (sqlite3.OperationalError) misuse of window function AVG()\n",
      "[SQL: SELECT PF, AVG(CAST(REPLACE(PROF_LOSS, 'PROFFIT', '1') AS REAL)) AS avg_profit,SUM((CAST(REPLACE(PROF_LOSS, 'PROFFIT', '1') AS REAL) - AVG(CAST(REPLACE(PROF_LOSS, 'PROFFIT', '1') AS REAL)) OVER (PARTITION BY PF)) * (CAST(REPLACE(PROF_LOSS, 'PROFFIT', '1') AS REAL) - AVG(CAST(REPLACE(PROF_LOSS, 'PROFFIT', '1') AS REAL)) OVER (PARTITION BY PF))) / COUNT(*) AS variance FROM title_data GROUP BY PF ORDER BY variance ASC]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8). Skipping the query\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,055 - INFO ==> State: sql_result | 38/42 SQL script executed, 1 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,055 - INFO ==> State: sql_result | 39/42 SQL script executed, 3 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,056 - INFO ==> State: sql_result | 40/42 SQL script executed, 1 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,056 - INFO ==> State: sql_result | 41/42 SQL script executed, 1 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,057 - INFO ==> State: sql_result | SQL script execution completed, 30 passed, 4 failed, 8 overlength\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,069 - INFO ==> State: sql_result | SQL result generation completed, saved the result to cache and set the cache flag to True\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,069 - INFO ==> State: bucket_query_generation | Initializing the agent to generate bucket queries\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,084 - INFO ==> State: bucket_query_generation | Bucket queries generated\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:54,085 - INFO ==> State: final_result | Initializing the agent to generate final result\u001b[0m\n",
      "\u001b[1;36m2025-03-10 22:32:54,317 - DEBUG ==> Initialized GeminiModel with model gemini-2.0-flash-001 , project hackathon0-project, location us-central1\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:32:57,406 - INFO ==> State: final_result | 0/2 Final result generated from the bucket query. The primary driver of overall ...\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:32:57,994 - WARNING ==> Rate limit hit. Retrying in 30 seconds... (Attempt 1/5)\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:33:32,296 - INFO ==> State: final_result | 1/2 Final result generated from the bucket query. The average Net Profit/Loss (N...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:33:32,301 - INFO ==> State: final_result | Final result generation completed, saved the result to cache and set the cache flag to True\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:33:32,303 - INFO ==> Ending the agent-assist\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "MY_AGENT.continue_flow({\n",
    "    'state': 'start',\n",
    "    'model':{\n",
    "        'model_name':'gemini-2.0-flash-001',\n",
    "        'temperature': 0.5,\n",
    "        'max_output_tokens': 512,\n",
    "        'max_retries':5,\n",
    "        'wait_time':30\n",
    "    },\n",
    "    'results':{\n",
    "        'refine_old_summaries':[],\n",
    "        'subj_query_generation':[],\n",
    "        'stat_query_generation':[],\n",
    "        'register_data':[],\n",
    "        'sql_script_generation':[],\n",
    "        'sql_result':[],\n",
    "        'bucket_query_generation':[],\n",
    "        'final_result':[]\n",
    "    },\n",
    "    'cache_location':{\n",
    "        \"sample_summarized_pnl_commentaries\":\"../sample_data/sample_summarized_pnl_commentaries.json\",\n",
    "        \"rule_based_title_comment_data\":\"../sample_data/rule_based_title_comment_data.json\",\n",
    "\n",
    "        \"state_config\":\"../sample_data/cached/state_config.json\",\n",
    "        \n",
    "        \"refine_old_summaries\":\"../sample_data/cached/refine_old_summaries.json\",\n",
    "        \"subj_query_generation\":\"../sample_data/cached/subj_query_generation.json\",\n",
    "        \"stat_query_generation\":\"../sample_data/cached/stat_query_generation.json\",\n",
    "        \"register_data\":\"../sample_data/cached/register_data.json\",\n",
    "        \"sql_script_generation\":\"../sample_data/cached/sql_script_generation.json\",\n",
    "        \"sql_result\":\"../sample_data/cached/sql_result.json\",\n",
    "        \"bucket_query_generation\":\"../sample_data/cached/bucket_query_generation.json\",\n",
    "        \"final_result\":\"../sample_data/cached/final_result.json\"\n",
    "    },\n",
    "    'cache_flag':{\n",
    "        \"refine_old_summaries\":False,\n",
    "        \"subj_query_generation\":False,\n",
    "        \"stat_query_generation\":False,\n",
    "        \"register_data\":False,\n",
    "        \"sql_script_generation\":False,\n",
    "        \"sql_result\":False,\n",
    "        \"bucket_query_generation\":False,\n",
    "        \"final_result\":False\n",
    "    }\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "snap = MY_AGENT.get_recent_state_snap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall, the top 5 factors impacting net profit/loss were Credit Spread (+€204m), Bond Basis (+€200m), IRGamma (+€193m), Theta (+€184m), and FXDelta (+€171m). However, specific desks, particularly US/LDN and LATAM/NYC, experienced the lowest net profit/loss.\n",
      "\n",
      "Analyzing portfolio performance, the American London CEEMAEA Portfolio stands out with the highest overall net profit (+€392m), followed by LATAM Emerging (+€380m) and European CEEMAEA (+€346m). Within the American London CEEMAEA Portfolio, Bond Basis contributed +€78m, Credit Spread +€61m, FXDelta +€58m, IRDelta +€63m, and IRGamma +€67m.\n",
      "\n",
      "Business unit performance, broken down by currency, reveals that CEEMAEA's net profit was significantly influenced by INR (+€94m), MXN (+€83m), CZK (+€82m), EUR (+€79m), and BRL (+€75m). However, some CEEMAEA and LATAM business units experienced the lowest net profit/loss overall.\n",
      "\n",
      "Desk-level analysis shows that Bond Basis had a significant impact on LATAM/NYC DSK (+€81m), while Credit Spread and IRGamma were key drivers for EU/LDN DSK (+€76m and +€74m respectively). Credit Spread also had a substantial impact on US/LDN DSK (+€68m), and Bond Basis contributed significantly to EU/LDN DSK (+€66m).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(snap['results']['final_result'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average Net Profit/Loss (NET) across all transactions is approximately €1.01 million, with a total sum of €1.12 billion across 1103 transactions. The skewness of 0.015 and kurtosis of -1.29 indicate a near-normal distribution with slightly flatter tails.\n",
      "\n",
      "**Business Unit (BUIS) Performance:** Both CEEMAEA and LATAM Business Units show an equal distribution of profit and loss transactions, with a sum of €0.\n",
      "\n",
      "**Currency (CUR) Performance:** The top-performing currencies by average NET are INR (€1.05m), GBP (€1.05m), and EUR (€1.04m). The bottom-performing currencies are BRL (€0.90m) and USD (€0.97m). USD has the highest total profit with €0.\n",
      "\n",
      "**Portfolio (PF) Performance:** Among the bottom three portfolios by average NET, American London CEEMAEA Portfolio has the highest average NET at €1.06m, followed by LATAM Emerging Portfolio (€1.03m) and European CEEMAEA Portfolio (€0.95m). The portfolios with the highest standard deviation in NET are European CEEMAEA Portfolio, American London CEEMAEA Portfolio, and LATAM Emerging Portfolio. All portfolios have an average profit of €0.\n",
      "\n",
      "**Desk (DSK) Performance:** The top three desks by average NET are US/LDN DSK (€1.03m), LATAM/NYC DSK (€1.02m), and EU/LDN DSK (€0.99m). EU/LDN DSK shows the highest variance in NET. EU/LDN DSK has the highest profit-to-loss ratio (1.12), followed by US/LDN DSK (1.05), while LATAM/NYC DSK has a lower ratio (0.80).\n",
      "\n",
      "**Factor Analysis:** BondBasis, CreditSpread, IRDelta, IRGamma, and FXDelta are the most frequent factors. IRGamma has the highest profit-to-loss ratio (1.02), while IRDelta has the lowest (0.86). BondBasis has the highest frequency of losses.\n",
      "\n",
      "**Volatility and Risk:** The standard deviation of NET profit/loss is significant for both CEEMAEA and LATAM Business Units, indicating high volatility.\n",
      "\n",
      "**Overall:** The overall performance shows a positive average NET profit/loss, but with significant variations across currencies, portfolios, and desks. Risk management should focus on the high volatility observed in CEEMAEA and LATAM Business Units and the factors contributing to losses, particularly BondBasis.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(snap['results']['final_result'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_change_state(old_state:AgentState, change_state_name:str, new_state_result:Dict[str, Any]):\n",
    "    state_name_array = [\n",
    "            'refine_old_summaries',\n",
    "            'subj_query_generation',\n",
    "            'stat_query_generation',\n",
    "            'register_data',\n",
    "            'sql_script_generation',\n",
    "            'sql_result',\n",
    "            'bucket_query_generation',\n",
    "            'final_result'\n",
    "    ]\n",
    "\n",
    "    schema_valid = validate_schema(change_state_name, new_state_result)\n",
    "    if not schema_valid:\n",
    "        LOGGER.error(f\"State: {change_state_name} | Manual change in state {change_state_name} not possible due to schema mismatch\")\n",
    "        return old_state\n",
    "\n",
    "    i = 0\n",
    "    for i in range(len(state_name_array)):\n",
    "      if state_name_array[i] == change_state_name:\n",
    "         break\n",
    "      \n",
    "    if change_state_name in ['refine_old_summaries', 'sql_script_generation']:\n",
    "        old_state['results'][change_state_name] = new_state_result\n",
    "        old_state['cache_flag'][change_state_name] = True\n",
    "        LOGGER.info(f\"State: {change_state_name} | Manual change in state {change_state_name} done both in RAM and Disk cache\")\n",
    "        save_json_data(old_state['cache_location'][change_state_name], {\"result\":new_state_result})\n",
    "        for j in range(i+1, len(state_name_array)):\n",
    "            old_state['results'][state_name_array[j]] = []\n",
    "            old_state['cache_flag'][state_name_array[j]] = False\n",
    "            save_json_data(old_state['cache_location'][state_name_array[j]], {\"result\":old_state['results'][state_name_array[j]]})\n",
    "            LOGGER.info(f\"State: {state_name_array[j]} | Manual RESET state {state_name_array[j]} done both in RAM and Disk cache\")\n",
    "\n",
    "    elif change_state_name in ['subj_query_generation', 'stat_query_generation']:\n",
    "        prev_result = old_state['results'][change_state_name]\n",
    "        id_to_content_mapping = {\n",
    "            result['id']:result for result in prev_result\n",
    "        }\n",
    "        \n",
    "        for result in new_state_result:\n",
    "            if result['id'] not in id_to_content_mapping or (result['id'] in id_to_content_mapping and result['query']!=id_to_content_mapping[result['id']]['query']):\n",
    "                result['id'] = hashlib.sha256(json.dumps(result).encode()).hexdigest()\n",
    "                result['flag'] = 'hot'\n",
    "                LOGGER.info(f\"Conflict in ID found for the query: {result['query'][:20]}... New ID generated and flag set to hot\")\n",
    "\n",
    "\n",
    "        old_state['results'][change_state_name] = new_state_result\n",
    "        old_state['cache_flag'][change_state_name] = True\n",
    "        save_json_data(old_state['cache_location'][change_state_name], {\"result\":new_state_result})\n",
    "        LOGGER.info(f\"State: {change_state_name} | Manual change in state {change_state_name} done both in RAM and Disk cache\")\n",
    "    \n",
    "    else:\n",
    "        LOGGER.warning(f\"State: {change_state_name} | Manual change in state {change_state_name} not possible\")\n",
    "\n",
    "    # Store the state\n",
    "    save_json_data(old_state['cache_location']['state_config'], old_state)\n",
    "    LOGGER.info(f\"State: {change_state_name} | State config saved to disk cache\")\n",
    "\n",
    "    return old_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_snap = load_json_data(\"../sample_data/cached/state_config.json\")\n",
    "new_snap = load_json_data(\"../sample_data/cached/state_config.json\")\n",
    "new_snap['results']['subj_query_generation'][3]['query'] = \"Mannually changed\"+new_snap['results']['subj_query_generation'][3]['query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'What are the <FACTOR>s that contributed the highest <NET> profit/loss?',\n",
       "  'id': 'c294e38e35f0166be6daac7b2ed4e41ec670357c93e08ac5f175338e5d2ed726',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'Which <CUR> currencies are driving the top-performing portfolios <PF>?',\n",
       "  'id': '04b738ec04a399bdbdb8728b17d980178e00dc7918943bc264c11a82b3093b2f',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'What is the average <NET> profit/loss for <BUIS> by <DATE>?',\n",
       "  'id': '4c5ec8435be11380c73fa867c0c29e18d1d07efecb4c6a2c691a423963bfe68e',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'List the top 5 <BUIS> with the highest <NET> profits.',\n",
       "  'id': '0421c8eabb7eb2cf943c64ea36ea1fe08e370967b08e5c02f79499b886824caf',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'List the bottom 5 <BUIS> with the lowest <NET> losses.',\n",
       "  'id': 'c4b85835ada7791539b9eb3d0b782d2c1ddf9b275ba7bf7a11f9a3dd52a96106',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'What is the sum of <NET> profit/loss for each <PF>?',\n",
       "  'id': '6286e637c0127eccac3d809fc400e83c50cbfeb058758fb1924e40633ffcc489',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'What is the maximum <NET> profit for <BUIS> on <DATE>?',\n",
       "  'id': '3413e8ae4e062d337323259c616806209c6e3aabd5ba68d5ba67eeb537aa085a',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'What is the minimum <NET> loss for <BUIS> on <DATE>?',\n",
       "  'id': '970d4b0c54cbb8234f2b74d850c205331481b2627beaefc75c0523d0aaa3d985',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'What are the top 5 <DSK> with the highest <NET> profit/loss?',\n",
       "  'id': '88c73cdf5d132bfc71e9ccc473f44a3a686f0fd895097252c1b1e3af2546453e',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'What are the bottom 5 <DSK> with the lowest <NET> profit/loss?',\n",
       "  'id': '3ace89b46b541f985a67bfef87ca26ba28e0cba9b9ab563b75034ba13df25f9c',\n",
       "  'flag': 'cold'}]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_snap['results']['subj_query_generation'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'What are the <FACTOR>s that contributed the highest <NET> profit/loss?',\n",
       "  'id': 'c294e38e35f0166be6daac7b2ed4e41ec670357c93e08ac5f175338e5d2ed726',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'Which <CUR> currencies are driving the top-performing portfolios <PF>?',\n",
       "  'id': '04b738ec04a399bdbdb8728b17d980178e00dc7918943bc264c11a82b3093b2f',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'What is the average <NET> profit/loss for <BUIS> by <DATE>?',\n",
       "  'id': '4c5ec8435be11380c73fa867c0c29e18d1d07efecb4c6a2c691a423963bfe68e',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'Mannually changedList the top 5 <BUIS> with the highest <NET> profits.',\n",
       "  'id': '0421c8eabb7eb2cf943c64ea36ea1fe08e370967b08e5c02f79499b886824caf',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'List the bottom 5 <BUIS> with the lowest <NET> losses.',\n",
       "  'id': 'c4b85835ada7791539b9eb3d0b782d2c1ddf9b275ba7bf7a11f9a3dd52a96106',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'What is the sum of <NET> profit/loss for each <PF>?',\n",
       "  'id': '6286e637c0127eccac3d809fc400e83c50cbfeb058758fb1924e40633ffcc489',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'What is the maximum <NET> profit for <BUIS> on <DATE>?',\n",
       "  'id': '3413e8ae4e062d337323259c616806209c6e3aabd5ba68d5ba67eeb537aa085a',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'What is the minimum <NET> loss for <BUIS> on <DATE>?',\n",
       "  'id': '970d4b0c54cbb8234f2b74d850c205331481b2627beaefc75c0523d0aaa3d985',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'What are the top 5 <DSK> with the highest <NET> profit/loss?',\n",
       "  'id': '88c73cdf5d132bfc71e9ccc473f44a3a686f0fd895097252c1b1e3af2546453e',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'What are the bottom 5 <DSK> with the lowest <NET> profit/loss?',\n",
       "  'id': '3ace89b46b541f985a67bfef87ca26ba28e0cba9b9ab563b75034ba13df25f9c',\n",
       "  'flag': 'cold'}]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_snap['results']['subj_query_generation'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_schema('subj_query_generation', new_snap['results']['subj_query_generation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m2025-03-11 00:09:18,823 - INFO ==> Conflict in ID found for the query: Mannually changedLis... New ID generated and flag set to hot\u001b[0m\n",
      "\u001b[1;32m2025-03-11 00:09:18,825 - INFO ==> State: subj_query_generation | Manual change in state subj_query_generation done both in RAM and Disk cache\u001b[0m\n",
      "\u001b[1;32m2025-03-11 00:09:18,847 - INFO ==> State: subj_query_generation | State config saved to disk cache\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "changed_state = manual_change_state(old_snap, 'subj_query_generation', new_snap['results']['subj_query_generation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'What are the <FACTOR>s that contributed the highest <NET> profit/loss?',\n",
       "  'id': 'c294e38e35f0166be6daac7b2ed4e41ec670357c93e08ac5f175338e5d2ed726',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'Which <CUR> currencies are driving the top-performing portfolios <PF>?',\n",
       "  'id': '04b738ec04a399bdbdb8728b17d980178e00dc7918943bc264c11a82b3093b2f',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'What is the average <NET> profit/loss for <BUIS> by <DATE>?',\n",
       "  'id': '4c5ec8435be11380c73fa867c0c29e18d1d07efecb4c6a2c691a423963bfe68e',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'Mannually changedList the top 5 <BUIS> with the highest <NET> profits.',\n",
       "  'id': '1fbf196a6ae57c6e63e71751a0e6e9b31a0c49af96f877104079a1aaf4155624',\n",
       "  'flag': 'hot'},\n",
       " {'query': 'List the bottom 5 <BUIS> with the lowest <NET> losses.',\n",
       "  'id': 'c4b85835ada7791539b9eb3d0b782d2c1ddf9b275ba7bf7a11f9a3dd52a96106',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'What is the sum of <NET> profit/loss for each <PF>?',\n",
       "  'id': '6286e637c0127eccac3d809fc400e83c50cbfeb058758fb1924e40633ffcc489',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'What is the maximum <NET> profit for <BUIS> on <DATE>?',\n",
       "  'id': '3413e8ae4e062d337323259c616806209c6e3aabd5ba68d5ba67eeb537aa085a',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'What is the minimum <NET> loss for <BUIS> on <DATE>?',\n",
       "  'id': '970d4b0c54cbb8234f2b74d850c205331481b2627beaefc75c0523d0aaa3d985',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'What are the top 5 <DSK> with the highest <NET> profit/loss?',\n",
       "  'id': '88c73cdf5d132bfc71e9ccc473f44a3a686f0fd895097252c1b1e3af2546453e',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'What are the bottom 5 <DSK> with the lowest <NET> profit/loss?',\n",
       "  'id': '3ace89b46b541f985a67bfef87ca26ba28e0cba9b9ab563b75034ba13df25f9c',\n",
       "  'flag': 'cold'}]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changed_state['results']['subj_query_generation'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m2025-03-10 22:52:21,762 - INFO ==> Starting the agent-assist\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:21,768 - INFO ==> State: refine_old_summaries | Initializing the agent to refine old summaries\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:21,769 - INFO ==> State: refine_old_summaries | Loaded cached data and skipping the model, 3 old result found\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:21,771 - INFO ==> State: subj_query_generation | Initializing the agent to refine old summaries\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:21,774 - INFO ==> State: subj_query_generation | Loaded cached data and skipping the model, 15 old result found\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:21,777 - INFO ==> State: stat_query_generation | Initializing the agent to refine old summaries\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:21,778 - INFO ==> State: stat_query_generation | Loaded cached data and skipping the model, 27 old result found\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:21,782 - INFO ==> State: register_data | Initializing the agent to register data\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:21,891 - INFO ==> State: register_data | Data registration completed, saved the data to in-memory DB. Global variable TITLE_DATA_INMEM_DB is set\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:21,892 - INFO ==> State: sql_script_generation | Initializing the agent to generate SQL script\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:21,895 - INFO ==> State: sql_script_generation | Loaded cached data and skipping the model, 42 old result found\u001b[0m\n",
      "\u001b[1;36m2025-03-10 22:52:22,123 - DEBUG ==> Initialized GeminiModel with model gemini-2.0-flash-001 , project hackathon0-project, location us-central1\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:22,126 - INFO ==> State: sql_script_generation | 0/42 SQL script loaded from cache for the query: What are the <FACTOR ... to SELECT FACTOR FROM t ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:22,127 - INFO ==> State: sql_script_generation | 1/42 SQL script loaded from cache for the query: Which <CUR> currenci ... to SELECT CUR, PF FROM  ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:22,127 - INFO ==> State: sql_script_generation | 2/42 SQL script loaded from cache for the query: What is the average  ... to SELECT BUIS, DATE, A ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,419 - INFO ==> State: sql_script_generation | 3/42 SQL script generated for the query: Mannually changedLis ... to SELECT BUIS FROM tit ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,421 - INFO ==> State: sql_script_generation | 3/42 Query flag changed to cold\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,422 - INFO ==> State: sql_script_generation | 4/42 SQL script loaded from cache for the query: List the bottom 5 <B ... to SELECT BUIS FROM tit ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,423 - INFO ==> State: sql_script_generation | 5/42 SQL script loaded from cache for the query: What is the sum of < ... to SELECT PF, SUM(NET)  ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,424 - INFO ==> State: sql_script_generation | 6/42 SQL script loaded from cache for the query: What is the maximum  ... to SELECT BUIS, DATE, m ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,425 - INFO ==> State: sql_script_generation | 7/42 SQL script loaded from cache for the query: What is the minimum  ... to SELECT BUIS, DATE, m ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,425 - INFO ==> State: sql_script_generation | 8/42 SQL script loaded from cache for the query: What are the top 5 < ... to SELECT DSK FROM titl ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,426 - INFO ==> State: sql_script_generation | 9/42 SQL script loaded from cache for the query: What are the bottom  ... to SELECT DSK FROM titl ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,427 - INFO ==> State: sql_script_generation | 10/42 SQL script loaded from cache for the query: What is the average  ... to SELECT CUR, AVG(NET) ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,427 - INFO ==> State: sql_script_generation | 11/42 SQL script loaded from cache for the query: What is the sum of < ... to SELECT FACTOR, SUM(N ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,428 - INFO ==> State: sql_script_generation | 12/42 SQL script loaded from cache for the query: What are the top 5 < ... to SELECT PF FROM title ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,429 - INFO ==> State: sql_script_generation | 13/42 SQL script loaded from cache for the query: What are the bottom  ... to SELECT PF FROM title ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,430 - INFO ==> State: sql_script_generation | 14/42 SQL script loaded from cache for the query: What is the mean <NE ... to SELECT BUIS, DATE, A ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,430 - INFO ==> State: sql_script_generation | 15/42 SQL script loaded from cache for the query: What is average, max ... to SELECT AVG(NET), MAX ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,431 - INFO ==> State: sql_script_generation | 16/42 SQL script loaded from cache for the query: What is average, max ... to SELECT BUIS, AVG(CAS ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,431 - INFO ==> State: sql_script_generation | 17/42 SQL script loaded from cache for the query: What is average, max ... to SELECT CUR, AVG(NET) ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,432 - INFO ==> State: sql_script_generation | 18/42 SQL script loaded from cache for the query: What is average, max ... to WITH PortfolioAverag ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,432 - INFO ==> State: sql_script_generation | 19/42 SQL script loaded from cache for the query: What is average, max ... to SELECT PF, AVG(NET), ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,433 - INFO ==> State: sql_script_generation | 20/42 SQL script loaded from cache for the query: What is average, max ... to WITH DeskSummary AS  ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,433 - INFO ==> State: sql_script_generation | 21/42 SQL script loaded from cache for the query: What is average, max ... to SELECT AVG(NET), MAX ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,434 - INFO ==> State: sql_script_generation | 22/42 SQL script loaded from cache for the query: What are the top cur ... to SELECT CUR, AVG(NET) ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,434 - INFO ==> State: sql_script_generation | 23/42 SQL script loaded from cache for the query: What are the bottom  ... to SELECT CUR, AVG(NET) ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,435 - INFO ==> State: sql_script_generation | 24/42 SQL script loaded from cache for the query: What is the total co ... to SELECT FACTOR, count ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,435 - INFO ==> State: sql_script_generation | 25/42 SQL script loaded from cache for the query: What is the percenta ... to SELECT FACTOR, (SUM( ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,436 - INFO ==> State: sql_script_generation | 26/42 SQL script loaded from cache for the query: What is the trend of ... to SELECT DATE, sum(NET ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,436 - INFO ==> State: sql_script_generation | 27/42 SQL script loaded from cache for the query: What is the moving a ... to SELECT DATE, AVG(NET ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,437 - INFO ==> State: sql_script_generation | 28/42 SQL script loaded from cache for the query: What is the standard ... to SELECT BUIS, SUM(NET ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,438 - INFO ==> State: sql_script_generation | 29/42 SQL script loaded from cache for the query: What is the correlat ... to SELECT corr(CASE WHE ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,438 - INFO ==> State: sql_script_generation | 30/42 SQL script loaded from cache for the query: What is the skewness ... to \n",
      "WITH\n",
      "  Data AS (\n",
      "   ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,438 - INFO ==> State: sql_script_generation | 31/42 SQL script loaded from cache for the query: Which <PF> portfolio ... to SELECT PF, SUM(NET * ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,439 - INFO ==> State: sql_script_generation | 32/42 SQL script loaded from cache for the query: Which <DSK> desks ha ... to SELECT DSK, SUM(NET  ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,440 - INFO ==> State: sql_script_generation | 33/42 SQL script loaded from cache for the query: What is the probabil ... to SELECT NET, PROF_LOS ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,440 - INFO ==> State: sql_script_generation | 34/42 SQL script loaded from cache for the query: What is the cumulati ... to SELECT DATE, SUM(NET ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,440 - INFO ==> State: sql_script_generation | 35/42 SQL script loaded from cache for the query: Which <CUR> currency ... to SELECT CUR FROM titl ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,441 - INFO ==> State: sql_script_generation | 36/42 SQL script loaded from cache for the query: What is the ratio of ... to SELECT FACTOR, CAST( ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,441 - INFO ==> State: sql_script_generation | 37/42 SQL script loaded from cache for the query: Which <PF> portfolio ... to SELECT PF, AVG(CAST( ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,441 - INFO ==> State: sql_script_generation | 38/42 SQL script loaded from cache for the query: Which <FACTOR> contr ... to SELECT FACTOR, SUM(P ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,442 - INFO ==> State: sql_script_generation | 39/42 SQL script loaded from cache for the query: What is the ratio of ... to SELECT DSK, SUM(CASE ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,442 - INFO ==> State: sql_script_generation | 40/42 SQL script loaded from cache for the query: Which <CUR> currency ... to SELECT CUR, SUM(PROF ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,443 - INFO ==> State: sql_script_generation | 41/42 SQL script loaded from cache for the query: Which <FACTOR> has t ... to SELECT FACTOR FROM t ...\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,445 - INFO ==> State: sql_script_generation | SQL script generation completed, saved the result to cache and set the cache flag to True\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,447 - INFO ==> State: sql_script_generation | Saved the previous state subj_query_generation and stat_query_generation results to cache with proper all cold flag\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,448 - INFO ==> State: sql_result | Initializing the agent to generate SQL result\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,452 - INFO ==> State: sql_result | 0/42 SQL script executed, 1 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,453 - INFO ==> State: sql_result | 1/42 SQL script executed, 10 rows returned\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:52:24,459 - WARNING ==> State: sql_result | 2/42 SQL script executed, 562 rows returned. Too many rows returned, consider refining the query\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,460 - INFO ==> State: sql_result | 3/42 SQL script executed, 5 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,460 - INFO ==> State: sql_result | 4/42 SQL script executed, 5 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,461 - INFO ==> State: sql_result | 5/42 SQL script executed, 3 rows returned\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:52:24,464 - WARNING ==> State: sql_result | 6/42 SQL script executed, 562 rows returned. Too many rows returned, consider refining the query\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:52:24,465 - WARNING ==> State: sql_result | 7/42 SQL script executed, 404 rows returned. Too many rows returned, consider refining the query\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,466 - INFO ==> State: sql_result | 8/42 SQL script executed, 5 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,466 - INFO ==> State: sql_result | 9/42 SQL script executed, 5 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,467 - INFO ==> State: sql_result | 10/42 SQL script executed, 7 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,468 - INFO ==> State: sql_result | 11/42 SQL script executed, 6 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,468 - INFO ==> State: sql_result | 12/42 SQL script executed, 5 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,469 - INFO ==> State: sql_result | 13/42 SQL script executed, 5 rows returned\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:52:24,470 - WARNING ==> State: sql_result | 14/42 SQL script executed, 562 rows returned. Too many rows returned, consider refining the query\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,471 - INFO ==> State: sql_result | 15/42 SQL script executed, 1 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,471 - INFO ==> State: sql_result | 16/42 SQL script executed, 2 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,472 - INFO ==> State: sql_result | 17/42 SQL script executed, 7 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,474 - INFO ==> State: sql_result | 18/42 SQL script executed, 3 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,475 - INFO ==> State: sql_result | 19/42 SQL script executed, 3 rows returned\u001b[0m\n",
      "\u001b[1;31m2025-03-10 22:52:24,475 - ERROR ==> State: sql_result | 20/42 SQL script execution failed: (sqlite3.OperationalError) ambiguous column name: DSK\n",
      "[SQL: WITH DeskSummary AS (SELECT DSK, AVG(NET) AS avg_net, MAX(NET) AS max_net, MIN(NET) AS min_net, SUM(NET) AS sum_net, COUNT(NET) AS count_net FROM title_data GROUP BY DSK ORDER BY SUM(NET) DESC LIMIT 5) SELECT DSK, avg_net, max_net, min_net, sum_net, count_net, SUM((title_data.NET - DeskSummary.avg_net) * (title_data.NET - DeskSummary.avg_net)) / DeskSummary.count_net AS variance FROM title_data JOIN DeskSummary ON title_data.DSK = DeskSummary.DSK GROUP BY DSK, avg_net, max_net, min_net, sum_net, count_net ORDER BY sum_net DESC]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8). Skipping the query\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,476 - INFO ==> State: sql_result | 21/42 SQL script executed, 3 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,477 - INFO ==> State: sql_result | 22/42 SQL script executed, 7 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,478 - INFO ==> State: sql_result | 23/42 SQL script executed, 5 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,478 - INFO ==> State: sql_result | 24/42 SQL script executed, 6 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,479 - INFO ==> State: sql_result | 25/42 SQL script executed, 6 rows returned\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:52:24,480 - WARNING ==> State: sql_result | 26/42 SQL script executed, 281 rows returned. Too many rows returned, consider refining the query\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:52:24,481 - WARNING ==> State: sql_result | 27/42 SQL script executed, 281 rows returned. Too many rows returned, consider refining the query\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,482 - INFO ==> State: sql_result | 28/42 SQL script executed, 2 rows returned\u001b[0m\n",
      "\u001b[1;31m2025-03-10 22:52:24,482 - ERROR ==> State: sql_result | 29/42 SQL script execution failed: (sqlite3.OperationalError) no such function: corr\n",
      "[SQL: SELECT corr(CASE WHEN FACTOR = 'BondBasis' THEN 1 WHEN FACTOR = 'FXDelta' THEN 2 WHEN FACTOR = 'IRDelta' THEN 3 ELSE 0 END, CAST(NET AS REAL)) FROM title_data]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8). Skipping the query\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,483 - INFO ==> State: sql_result | 30/42 SQL script executed, 1 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,484 - INFO ==> State: sql_result | 31/42 SQL script executed, 3 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,484 - INFO ==> State: sql_result | 32/42 SQL script executed, 3 rows returned\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:52:24,486 - WARNING ==> State: sql_result | 33/42 SQL script executed, 1103 rows returned. Too many rows returned, consider refining the query\u001b[0m\n",
      "\u001b[1;33m2025-03-10 22:52:24,488 - WARNING ==> State: sql_result | 34/42 SQL script executed, 1103 rows returned. Too many rows returned, consider refining the query\u001b[0m\n",
      "\u001b[1;31m2025-03-10 22:52:24,488 - ERROR ==> State: sql_result | 35/42 SQL script execution failed: (sqlite3.OperationalError) misuse of aggregate function AVG()\n",
      "[SQL: SELECT CUR FROM title_data GROUP BY CUR ORDER BY SUM((NET - AVG(NET)) * (NET - AVG(NET))) DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8). Skipping the query\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,489 - INFO ==> State: sql_result | 36/42 SQL script executed, 6 rows returned\u001b[0m\n",
      "\u001b[1;31m2025-03-10 22:52:24,489 - ERROR ==> State: sql_result | 37/42 SQL script execution failed: (sqlite3.OperationalError) misuse of window function AVG()\n",
      "[SQL: SELECT PF, AVG(CAST(REPLACE(PROF_LOSS, 'PROFFIT', '1') AS REAL)) AS avg_profit,SUM((CAST(REPLACE(PROF_LOSS, 'PROFFIT', '1') AS REAL) - AVG(CAST(REPLACE(PROF_LOSS, 'PROFFIT', '1') AS REAL)) OVER (PARTITION BY PF)) * (CAST(REPLACE(PROF_LOSS, 'PROFFIT', '1') AS REAL) - AVG(CAST(REPLACE(PROF_LOSS, 'PROFFIT', '1') AS REAL)) OVER (PARTITION BY PF))) / COUNT(*) AS variance FROM title_data GROUP BY PF ORDER BY variance ASC]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8). Skipping the query\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,490 - INFO ==> State: sql_result | 38/42 SQL script executed, 1 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,490 - INFO ==> State: sql_result | 39/42 SQL script executed, 3 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,491 - INFO ==> State: sql_result | 40/42 SQL script executed, 1 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,491 - INFO ==> State: sql_result | 41/42 SQL script executed, 1 rows returned\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,492 - INFO ==> State: sql_result | SQL script execution completed, 30 passed, 4 failed, 8 overlength\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,504 - INFO ==> State: sql_result | SQL result generation completed, saved the result to cache and set the cache flag to True\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,506 - INFO ==> State: bucket_query_generation | Initializing the agent to generate bucket queries\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,519 - INFO ==> State: bucket_query_generation | Bucket queries generated\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,519 - INFO ==> State: final_result | Initializing the agent to generate final result\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,522 - INFO ==> State: final_result | Loaded cached data and skipping the model, 2 old result found\u001b[0m\n",
      "\u001b[1;32m2025-03-10 22:52:24,522 - INFO ==> Ending the agent-assist\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "snap = MY_AGENT.continue_flow(changed_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'What are the <FACTOR>s that contributed the highest <NET> profit/loss?',\n",
       "  'id': 'c294e38e35f0166be6daac7b2ed4e41ec670357c93e08ac5f175338e5d2ed726',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'Which <CUR> currencies are driving the top-performing portfolios <PF>?',\n",
       "  'id': '04b738ec04a399bdbdb8728b17d980178e00dc7918943bc264c11a82b3093b2f',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'What is the average <NET> profit/loss for <BUIS> by <DATE>?',\n",
       "  'id': '4c5ec8435be11380c73fa867c0c29e18d1d07efecb4c6a2c691a423963bfe68e',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'Mannually changedList the top 5 <BUIS> with the highest <NET> profits.',\n",
       "  'id': '1fbf196a6ae57c6e63e71751a0e6e9b31a0c49af96f877104079a1aaf4155624',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'List the bottom 5 <BUIS> with the lowest <NET> losses.',\n",
       "  'id': 'c4b85835ada7791539b9eb3d0b782d2c1ddf9b275ba7bf7a11f9a3dd52a96106',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'What is the sum of <NET> profit/loss for each <PF>?',\n",
       "  'id': '6286e637c0127eccac3d809fc400e83c50cbfeb058758fb1924e40633ffcc489',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'What is the maximum <NET> profit for <BUIS> on <DATE>?',\n",
       "  'id': '3413e8ae4e062d337323259c616806209c6e3aabd5ba68d5ba67eeb537aa085a',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'What is the minimum <NET> loss for <BUIS> on <DATE>?',\n",
       "  'id': '970d4b0c54cbb8234f2b74d850c205331481b2627beaefc75c0523d0aaa3d985',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'What are the top 5 <DSK> with the highest <NET> profit/loss?',\n",
       "  'id': '88c73cdf5d132bfc71e9ccc473f44a3a686f0fd895097252c1b1e3af2546453e',\n",
       "  'flag': 'cold'},\n",
       " {'query': 'What are the bottom 5 <DSK> with the lowest <NET> profit/loss?',\n",
       "  'id': '3ace89b46b541f985a67bfef87ca26ba28e0cba9b9ab563b75034ba13df25f9c',\n",
       "  'flag': 'cold'}]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snap['results']['subj_query_generation'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'query': 'List the top 5 <BUIS> with the highest <NET> profits.',\n",
    "#   'id': '0421c8eabb7eb2cf943c64ea36ea1fe08e370967b08e5c02f79499b886824caf',\n",
    "#   'flag': 'cold'},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
